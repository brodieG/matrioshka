---
title: "Comparison of Programmable NSE Frameworks"
author: "Brodie Gaslam"
output:
    rmarkdown::html_vignette:
        toc: true
        css: styles.css

vignette: >
  %\VignetteIndexEntry{vetr}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

```{r global_options, echo=FALSE}
knitr::opts_chunk$set(error=TRUE, comment=NA)
library(dplyr)
library(recsub)
```

## An Ersatz Dplyr

We will implement a reduced-functionality copy of `dplyr` that supports the
`recsub` flavor of programmable NSE.  The interface is as follows:

```{r, eval=FALSE}
group_r <- function(x, ...) {...}     # similar to dplyr::group_by
filter_r <- function(x, subset) {...} # similar to dplyr::filter
summarize_r <- function(x, ...) {...} # similar to dplyr::summarise
```

`filter_r` and `group_r` are relatively simple, so we will focus on the
implementation of `summarize_r`.  For the other functions see the appendix.

```{r}
summarize_r <- function(x, ...)
  eval(bquote(.(summarize_r_l)(.(x), .(substitute(list(...))))), parent.frame())
```

`summarize_r` just forwards arguments to `summarize_r_l`, which does the heavy
work.  Notice how we use `bquote(.(summarize_r_l), ...)`

summarize_r_l <- function(x, els) {
  # Handle case where passed as a list or single exp
  exps.sub <- recsub(substitute(els), x, parent.frame())
  if(!is.call(exps.sub) || exps.sub[[1L]] != quote(list))
    exps.sub <- call("list", exps.sub)

  # compute groups and splits
  has.grp <- !is.null(attr(x, ".GRP")) && length(attr(x, ".GRP"))
  x <- as.data.frame(x)
  grps <- if(!has.grp) list(rep_len(1, nrow(x))) else attr(x, ".GRP")
  splits <- lapply(grps, eval, x, parent.frame())
  dat.split <- split(x, splits, drop=TRUE)
  grp.split <- if(has.grp) lapply(splits, split, splits, drop=TRUE)

  # compute the aggregations
  res.list <- lapply(
    dot_list(exps.sub),
    function(exp) lapply(dat.split, eval, expr=exp, enclos=parent.frame())
  )
  # Find max number of rows in each group, and recycle to that
  lens <- do.call(pmax, lapply(res.list, lengths, integer(length(splits))))
  res.list.r <- lapply(
    c(grp.split, res.list), function(x) unname(unlist(Map(rep_len, x, lens)))
  )
  as.data.frame(res.list.r)
}
```



group_r <- function(x, ...)
  eval(bquote(.(group_r_l)(.(x), .(substitute(list(...))))), parent.frame())
group_r_l <- function(x, els) {
  exps.sub <- recsub(substitute(els), x, .ENV)
  if(!is.call(exps.sub) || exps.sub[[1L]] != quote(list))
    exps.sub <- call("list", exps.sub)
  structure(x, .GRP=dot_list(exps.sub, "G"))
}
# == Summarizing ==

# == Filtering ==
filter_r <- function(x, subset) {
  sub.exp <- substitute(subset)
  sub.val <- evalr(sub.exp, envir=x, enclos=parent.frame())
  if(!is.null(sub.val))
    as.data.frame(x)[!is.na(sub.val) & sub.val, ] else x
}
# == Pipe ==
`%$%` <- function(x, y) {
  x.sub <- recsub(substitute(x), parent.frame())
  y.sub <- recsub(substitute(y), parent.frame())
  y.list <- if(!is.call(y.sub)) list(y.sub) else as.list(y.sub)

  sub_dat <- function(z, dat) {
    if(is.call(z)) {
      if(z[[1]] == as.name('%$%')) z[[2]] <- sub_dat(z[[2]], dat)
      else {
        z.list <- as.list(z)
        z <- as.call(c(z.list[1], list(dat), tail(z.list, -1)))
    } }
    z
  }
  eval(sub_dat(y.sub, x), parent.frame())
}
```
While `recsub` makes it easy to write programmable NSE functions, re-using those
functions inside others is a little trickier.

In order for things to work properly 

This is one area where more
complex NSE frameworks like `rlang` have an advantage.

## Poor Person's Dplyr


```{r}
dot_list <- function(x, pre="V") {
  dots <- tail(as.list(x), -1L)
  for(i in seq_along(dots))
    names(dots)[i] <- if(is.language(dots[[i]])) deparse(dots[[i]])[[1]]
      else sprintf("%s%d", pre, i)
  dots
}
# Grouping

group_r <- function(x, ...)
  eval(bquote(.(group_r_l)(.(x), .(substitute(list(...))))), parent.frame())
group_r_l <- function(x, els, .ENV=parent.frame()) {
  exps.sub <- recsub(substitute(els), x, .ENV)
  if(!is.call(exps.sub) || exps.sub[[1L]] != quote(list))
    exps.sub <- call("list", exps.sub)
  structure(x, .GRP=dot_list(exps.sub, "G"))
}
# == Summarizing ==

summarize_r <- function(x, ...)
  eval(bquote(.(summarize_r_l)(.(x), .(substitute(list(...))), parent.frame())))

summarize_r_l <- function(x, els) {
  # Handle case where passed as a list or single exp
  exps.sub <- recsub(substitute(els), x, parent.frame())
  if(!is.call(exps.sub) || exps.sub[[1L]] != quote(list))
    exps.sub <- call("list", exps.sub)

  # compute groups and splits
  has.grp <- !is.null(attr(x, ".GRP")) && length(attr(x, ".GRP"))
  x <- as.data.frame(x)
  grps <- if(!has.grp) list(rep_len(1, nrow(x))) else attr(x, ".GRP")
  splits <- lapply(grps, eval, x, parent.frame())
  dat.split <- split(x, splits, drop=TRUE)
  grp.split <- if(has.grp) lapply(splits, split, splits, drop=TRUE)

  # compute the aggregations
  res.list <- lapply(
    dot_list(exps.sub),
    function(exp) lapply(dat.split, eval, expr=exp, enclos=parent.frame())
  )
  # Find max number of rows in each group, and recycle to that
  lens <- do.call(pmax, lapply(res.list, lengths, integer(length(splits))))
  res.list.r <- lapply(
    c(grp.split, res.list), function(x) unname(unlist(Map(rep_len, x, lens)))
  )
  as.data.frame(res.list.r)
}
# == Filtering ==
filter_r <- function(x, subset) {
  sub.exp <- substitute(subset)
  sub.val <- evalr(sub.exp, envir=x, enclos=parent.frame())
  if(!is.null(sub.val))
    as.data.frame(x)[!is.na(sub.val) & sub.val, ] else x
}
# == Pipe ==
`%$%` <- function(x, y) {
  x.sub <- recsub(substitute(x), parent.frame())
  y.sub <- recsub(substitute(y), parent.frame())
  y.list <- if(!is.call(y.sub)) list(y.sub) else as.list(y.sub)

  sub_dat <- function(z, dat) {
    if(is.call(z)) {
      if(z[[1]] == as.name('%$%')) z[[2]] <- sub_dat(z[[2]], dat)
      else {
        z.list <- as.list(z)
        z <- as.call(c(z.list[1], list(dat), tail(z.list, -1)))
    } }
    z
  }
  eval(sub_dat(y.sub, x), parent.frame())
}
summ_by <- quote(group_by_r(group) %$% summarize_r(var))
group <- quote(group_r(species))
var <- quote(summarize_r(mean(height)))
group_var <- quote(group %$% var)

starwars %$% group_var

```



We want to re-implement `summarize_by` function introduced in the [userR 2017
Tidy Eval][1] session:

```{r}
summarise_by <- function(df, group, var) {
  group <- enquo(group)
  var <- enquo(var)
  df %>%
    group_by(!! group) %>%
    summarise(avg = mean(!! var))
}
summarise_by(starwars, species, height) %>% head(2)
```

With `recsub` we would use:

```{r}
summarise_by_r <- function(df, group, var) {
  group <- substitute(group)
  var <- substitute(var)
  expr <- recsub(
    bquote(
      .(df) %>%
      group_by(.(group)) %>%
      summarise(avg = mean(.(var)))
    ),
    df, parent.frame()
  )
  eval(expr, parent.frame())
}
summarise_by_r(starwars, species, height) %>% head(2)
```

While this looks a lot more complicated, keep in mind we just added programmable
NSE to something that has no idea `recsub` even exists.  `dplyr` implements its
own NSE with internal logic to handle the quo/dequo business.

With one advantage that we can do things like:

```{r}
my.var <- quote(species)
summarise_by_r(starwars, my.var, height) %>% head(2)
summarise_by(starwars, my.var, height) %>% head(2)
```

This would be even simpler if `group_by` and `summarise` had been built with
`recsub` to begin with:

```{r}
group_by_r <- function(.data, ..., add=FALSE) {
  group.call <- recsub(sys.call(), .data, parent.frame())
  group.call[[1]] <- quote(group_by)
  eval(group.call, parent.frame())
}
summarise_r <- function(.data, ..., add=FALSE) {
  summarise.call <- recsub(sys.call(), .data, parent.frame())
  summarise.call[[1]] <- quote(summarise)
  eval(summarise.call, parent.frame())
}
summarise_by_r2 <- function(df, group, var) {
  group <- substitute(group)
  var <- substitute(var)
  eval(
    bquote(.(df) %>% group_by_r(.(group)) %>% summarise_r(avg=mean(.(var)))),
    parent.frame()
  )
}
summarise_by_r2(starwars, species, height) %>% head(2)
summarise_by_r2(starwars, my.var, height) %>% head(2)

local({
  my.var <- quote(skin_color)
  summarise_by_r2(starwars, my.var, height) %>% head(2)
})
my.var <- quote(skin_color)
summarise_by_r2(starwars, my.var, height) %>% head(2)
```

need a function that will look at a substituted expression and decide whether
it needs to be wrapped in a list.  Some questions:

* how can we tell if it is a list or not?  Do we force it? But maybe it can't
  even be `evaled` under SE?
* Maybe rule is you must explicitly use `list`?  But if you do that, you can
  no longer pass a list as an argument?
* What about if we `recsub`, and check for `list`?  If we want an actual list we
  can just do `list(list())`
* I think in this case, the only issue is that if someone interjects and object
  `list` in the search path that isn't actually the list function, in which case
  we would get confused.  Would have to check that the found object on search
  path is the list we care about; I guess can just run a separate search for
  `list` to confirm.
* Also, right now we don't even substitute first position..., and there is the
  complication that in R-semantics a `list` non function object can't mask the
  base `list` object, so the rules at position one have to be different.
* So let's start with a normal recsub


```{r}

summ_by <- function(x, group, var) {
  eval(
    bquote(
      .(summarize_r_l)(
        .(group_r_l)(.(x), .(substitute(group))),
        mean(.(substitute(var)))
    ) ),
    parent.frame()
  )
}
# Data set:

DF <- cbind(
  USArrests, Divion=state.division, Region=state.region,
  Population=state.x77[, 1]
)



`[.super_df` <- function(x, i, j, by, drop=FALSE, .ENV=parent.frame()) {
  i.sub <- substitute(i)
  j.sub <- substitute(j)
  by.sub <- substitute(by)
  res.df <- eval(
    bquote(
      .(summarize_r_l)(
        .(group_r_l)(
          .(filter_r)(.(x), .(if(!missing(i.sub)) i.sub)),
          .(if(!missing(by.sub)) by.sub else quote(list()))
        ),
        .(if(!missing(j.sub)) j.sub else quote(list()))
    ) ),
    .ENV
  )
  as.super_df(res.df)
}

f <- function() browser()
y <- function() {
  print(parent.frame())
  evalq(f(), enclos=parent.frame())
}
local({
  a <- 'A'
  b <- 'B'
  y()
})

as.super_df <- function(x) {
  class(x) <- c("super_df", class(x))
  x
}
    bquote(
      .(summarize_r_l)(
        .(group_r_l)(
          .(filter_r)(.(NULL), .(if(!missing(i.sub)) i.sub)),
          .(if(!missing(by.sub)) by.sub else list())
        ),
        .(if(!missing(j.sub)) j.sub else list())
    ) )

starwars %$%
  filter_r(!is.na(hair_color)) %$%
  group_r(species, hair_color) %$%
  summarize_r(median(height), mean(mass))

sw <- as.super_df(starwars)
sw[, list(mean(height), max(mass)), list(species, hair_color)]

my.j <- quote(list(mean(height), max(mass)))
sw[, my.j, list(species, hair_color)]

sw[, mean(height), species]
sw[, mean(height, na.rm=T)]

my.grp.var <- quote(species)

var <- NA
local({
  hello <- "hello"
  var <- quote(height)
  e1 <- quote(max(var))
  e2 <- quote(min(var))
  exps <- list(quote(mean(var) / e1), quote(mean(var) / e2))
  lapply(exps, function(x) sw[!is.na(var), x])
})


my_sum <- function(.data, group, var) {
  eval(
    bquote(
      .(.data) %>%
        grp_by(.(substitute(group))) %>%
        summr(sum(.(substitute(var))), mean(.(substitute(var))))
    ),
    parent.frame()
  )
}
my_sum(iris, Species, Petal.Length)

```{r}
ll <- base::list
tf <- function(data, ...) {
  expr <- substitute(ll(...))
  vals <- eval(expr, data, parent.frame())
  vals
}
```


## References

[1]: https://schd.ws/hosted_files/user2017/43/tidyeval-user.pdf
[2]: https://www.r-project.org/dsc/2017/slides/tidyeval-hygienic-fexprs.pdf
